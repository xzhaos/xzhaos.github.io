<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimal-ui">
    <title>Xu&#x27;s AI Newsletter Oct 26, 2024</title>
    <link type="text/css" rel="stylesheet" href="assets/css/github-markdown.css">
    <link type="text/css" rel="stylesheet" href="assets/css/pilcrow.css">
    <link type="text/css" rel="stylesheet" href="assets/css/hljs-github.min.css"/>
  </head>
  <body>
    <article class="markdown-body"><h1 id="xus-ai-newsletter-oct-26-2024"><a class="header-link" href="#xus-ai-newsletter-oct-26-2024"></a>Xu&#39;s AI Newsletter Oct 26, 2024</h1>
<h2 id="anthropics-new-claude-ai-model-can-use-a-pc-the-way-people-do"><a class="header-link" href="#anthropics-new-claude-ai-model-can-use-a-pc-the-way-people-do"></a>Anthropic’s new Claude AI model can use a PC ‘the way people do’</h2>
<p>If you’re worried about artificial intelligence taking your job, you might want to sit down for this one. AI startup Anthropic has demonstrated a new “Claude” model called that can look at a computer screen and operate a virtual mouse and keyboard, “the way people do,” according to promotional material.</p>
<p>In the video demo, researcher Sam Ringer shows Claude performing a bit of data entry “drudge work,” with the AI model using screenshots of a Mac desktop to find relevant information and submit a form. It is indeed the kind of thing that employees all over the world do every day, though Ringer notes that this is a “representative example.” Exactly how much of the video is edited isn’t known.</p>
<p>[<a href="https://www.pcworld.com/article/2498806/anthropics-new-claude-ai-model-can-use-a-pc-the-way-people-do.html]">https://www.pcworld.com/article/2498806/anthropics-new-claude-ai-model-can-use-a-pc-the-way-people-do.html]</a></p>
<h3 id="editors-note"><a class="header-link" href="#editors-note"></a>Editor&#39;s Note</h3>
<p>Personally I don&#39;t like this use case. You basically hand over your digital life to AI which may do unexpected things without your knowledge. </p>
<h2 id="mother-says-ai-chatbot-led-her-son-to-kill-himself-in-lawsuit-against-its-maker"><a class="header-link" href="#mother-says-ai-chatbot-led-her-son-to-kill-himself-in-lawsuit-against-its-maker"></a>Mother says AI chatbot led her son to kill himself in lawsuit against its maker</h2>
<p>The mother of a teenager who killed himself after becoming obsessed with an artificial intelligence-powered chatbot now accuses its maker of complicity in his death.</p>
<p>Megan Garcia filed a civil suit against Character.ai, which makes a customizable chatbot for role-playing, in Florida federal court on Wednesday, alleging negligence, wrongful death and deceptive trade practices. Her son Sewell Setzer III, 14, died in Orlando, Florida, in February. In the months leading up to his death, Setzer used the chatbot day and night, according to Garcia.</p>
<p>[<a href="https://www.theguardian.com/technology/2024/oct/23/character-ai-chatbot-sewell-setzer-death]">https://www.theguardian.com/technology/2024/oct/23/character-ai-chatbot-sewell-setzer-death]</a></p>
<h3 id="editors-note-1"><a class="header-link" href="#editors-note-1"></a>Editor&#39;s Note</h3>
<p>This is the first known casualty of AI. We should have strong legal protection of human from AI. In general, it is not a good idea to have AI in the domain of human experience including psychology, affection, emotions, religion, politics, etc. AI should stay strictly in business, finance, science and technology domains. </p>
<h2 id="openais-agi-czar-quits-saying-the-company-isnt-ready-for-what-its-building"><a class="header-link" href="#openais-agi-czar-quits-saying-the-company-isnt-ready-for-what-its-building"></a>OpenAI&#39;s AGI Czar Quits, Saying the Company Isn&#39;t ready For What It&#39;s Building</h2>
<p>OpenAI&#39;s researcher in charge of making sure the company (and the world) is prepared for the advent of artificial general intelligence (AGI) has resigned — and is warning that nobody is ready for what&#39;s coming next.</p>
<p>In a post on his personal Substack, the firm&#39;s newly-resigned AGI readiness czar Miles Brundage said quitting his &quot;dream job&quot; after six years has been difficult. He says he&#39;s doing so because he feels a great responsibility regarding the purportedly human-level artificial intelligence he believes OpenAI is ushering into existence.</p>
<p>[<a href="https://futurism.com/the-byte/openai-agi-readiness-head-resigns]">https://futurism.com/the-byte/openai-agi-readiness-head-resigns]</a></p>
<h3 id="editors-note-2"><a class="header-link" href="#editors-note-2"></a>Editor&#39;s NOte</h3>
<p>Echoing previous story, we need a strong legal framework before AI can advance further. However, out of commercial interests, no one wants to slow down. Are we rushing to the point of no returns?</p>
<h2 id="openai-whistleblower-disgusted-that-his-job-was-to-vacuum-up-copyrighted-data-to-train-its-models"><a class="header-link" href="#openai-whistleblower-disgusted-that-his-job-was-to-vacuum-up-copyrighted-data-to-train-its-models"></a>OpenAI Whistleblower Disgusted That His Job Was to Vacuum Up Copyrighted Data to Train Its Models</h2>
<p>A former OpenAI researcher is blowing the whistle on the company&#39;s AI training practices, alleging that OpenAI violated copyright law to train its AI models — and arguing that OpenAI&#39;s current business model stands to upend the business of the internet as we know it, according to The New York Times.</p>
<p>The ex-staffer, a 25-year-old named Suchir Balaji, worked at OpenAI for four years before deciding to leave the AI firm due to ethical concerns. As Balaji sees it, because ChatGPT and other OpenAI products have become so heavily commercialized, OpenAI&#39;s practice of scraping online material en masse to feed its data-hungry AI models no longer satisfies the criteria of the fair use doctrine. OpenAI — which is currently facing several copyright lawsuits, including a high-profile case brought last year by the NYT — has argued the opposite.</p>
<p>[<a href="https://futurism.com/the-byte/openai-whistleblower-copyrighted-data]">https://futurism.com/the-byte/openai-whistleblower-copyrighted-data]</a></p>
<h3 id="editors-note-3"><a class="header-link" href="#editors-note-3"></a>Editor&#39;s Note</h3>
<p>OpenAI is now too much driven by commercial interest that it is willing to do whatever to stay ahead. </p>
<h2 id="programmers-hired-to-help-ai-learn-to-write-code-are-said-to-be-traitorous-to-software-developers-everywhere"><a class="header-link" href="#programmers-hired-to-help-ai-learn-to-write-code-are-said-to-be-traitorous-to-software-developers-everywhere"></a>Programmers Hired To Help AI Learn To Write Code Are Said To Be Traitorous To Software Developers Everywhere</h2>
<p>In today’s column, I discuss an increasingly angry question being heatedly debated about whether software developers who are aiding the data training of generative AI and large language models or LLMs are acting in a traitorous manner when doing so to improve AI-based code generation capabilities. The idea behind this is relatively simple. You could say that advancing AI toward generating programs and code will ultimately put all software developers out of a job.</p>
<p>[<a href="https://www.forbes.com/sites/lanceeliot/2024/10/23/are-programmers-hired-to-help-ai-learn-to-write-code-being-traitorous-to-software-developers-everywhere/]">https://www.forbes.com/sites/lanceeliot/2024/10/23/are-programmers-hired-to-help-ai-learn-to-write-code-being-traitorous-to-software-developers-everywhere/]</a></p>
<h3 id="editors-note-4"><a class="header-link" href="#editors-note-4"></a>Editor&#39;s Note</h3>
<p>Once upon a time, employees from advanced economies to train people in India or China so the work can be outsourced to low cost regions. At least the employment still happen somewhere. This time is quite different. </p>
    </article>
  </body>
</html>
