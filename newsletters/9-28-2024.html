<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimal-ui">
    <title>Xu&#x27;s AI Newsletter Sep 21, 2024</title>
    <link type="text/css" rel="stylesheet" href="assets/css/github-markdown.css">
    <link type="text/css" rel="stylesheet" href="assets/css/pilcrow.css">
    <link type="text/css" rel="stylesheet" href="assets/css/hljs-github.min.css"/>
  </head>
  <body>
    <article class="markdown-body"><h1 id="xus-ai-newsletter-sep-21-2024"><a class="header-link" href="#xus-ai-newsletter-sep-21-2024"></a>Xu&#39;s AI Newsletter Sep 21, 2024</h1>
<h2 id="the-ai-movie-era-is-here-but-openai-is-still-working-on-its-blockbuster"><a class="header-link" href="#the-ai-movie-era-is-here-but-openai-is-still-working-on-its-blockbuster"></a>The AI Movie Era Is Here, But OpenAI Is Still Working on Its Blockbuster</h2>
<p>The generative AI craze began with ChatGPT&#39;s text-based responses, but has evolved to include image generation and now text-to-video.</p>
<p>Four such tools launched this week, from Amazon, YouTube, Alibaba, and movie studio Lionsgate. They create videos from written descriptions (think: &quot;Create a video of a dog catching a ball&quot;), but the tech still has a long way to go.</p>
<p>YouTube&#39;s Veo tool can only create a green-screen-style background for its vertical clips, known as Shorts. Complete video clips (up to six seconds in length) will follow in 2025.</p>
<p>Amazon&#39;s tool helps sellers create simple advertisements—really simple. An example clip brings to life a static image of a coffee mug, and makes a video of it steaming against an artificial background. Details about Alibaba&#39;s tool are slim, but the announcement happened alongside the release of 100 open-source models, CNBC reports.</p>
<p>These tools pale in comparison to what OpenAI is promising with its Sora video generator, which can generate up to 60-second silent clips. (Google made similar promises for Veo at I/O in May.) When Sora debuted in February, it shocked the internet with hyper-realistic videos. Toys R Us even used it to whip up a commercial with a full storyline and flawless animation.</p>
<p>[<a href="https://www.pcmag.com/opinions/the-ai-movie-era-is-here-but-openai-is-still-working-on-its-blockbuster]">https://www.pcmag.com/opinions/the-ai-movie-era-is-here-but-openai-is-still-working-on-its-blockbuster]</a></p>
<h3 id="editors-note"><a class="header-link" href="#editors-note"></a>Editor&#39;s Note</h3>
<p>Videos are hardest to generate well. Whoever command this space will truly demonstrate their technical supremacy in Gen AI area. </p>
<h2 id="sam-altman-and-former-apple-executives-are-making-an-ai-device"><a class="header-link" href="#sam-altman-and-former-apple-executives-are-making-an-ai-device"></a>Sam Altman and former Apple executives are making an AI device</h2>
<p>The secret project already has a physical office space and 10 employees. Key staffers include Tang Tan, who headed product design teams for the iPhone and Apple Watch, and Evans Hankey, who succeeded Ive as Apple’s design chief.</p>
<p>Ive left Apple in July 2019 after nearly three decades with the iPhone maker, and founded his own design studio, LoveFrom, shortly after.</p>
<p>[<a href="https://qz.com/openai-lovefrom-altman-ive-jobs-ai-device-startup-1851654649]">https://qz.com/openai-lovefrom-altman-ive-jobs-ai-device-startup-1851654649]</a></p>
<h3 id="editors-note-1"><a class="header-link" href="#editors-note-1"></a>Editor&#39;s Note</h3>
<p>Could this new device eventually replace iPhone? </p>
<h2 id="openai-ceo-we-may-have-ai-superintelligence-in-a-few-thousand-days"><a class="header-link" href="#openai-ceo-we-may-have-ai-superintelligence-in-a-few-thousand-days"></a>OpenAI CEO: We may have AI superintelligence in “a few thousand days”</h2>
<p>On Monday, OpenAI CEO Sam Altman outlined his vision for an AI-driven future of tech progress and global prosperity in a new personal blog post titled &quot;The Intelligence Age.&quot; The essay paints a picture of human advancement accelerated by AI, with Altman suggesting that superintelligent AI could emerge within the next decade.</p>
<p>&quot;It is possible that we will have superintelligence in a few thousand days (!); it may take longer, but I’m confident we’ll get there,&quot; he wrote.</p>
<p>[<a href="https://arstechnica.com/information-technology/2024/09/ai-superintelligence-looms-in-sam-altmans-new-essay-on-the-intelligence-age/]">https://arstechnica.com/information-technology/2024/09/ai-superintelligence-looms-in-sam-altmans-new-essay-on-the-intelligence-age/]</a></p>
<h3 id="editors-note-2"><a class="header-link" href="#editors-note-2"></a>Editor&#39;s Note</h3>
<p>Is human ready for super-intelligence? I would rather this come later when we are all prepared. </p>
<h2 id="computer-maker-raspberry-pi-sees-robust-demand-for-first-ai-product"><a class="header-link" href="#computer-maker-raspberry-pi-sees-robust-demand-for-first-ai-product"></a>Computer Maker Raspberry Pi Sees ‘Robust Demand’ For First AI Product</h2>
<p>Raspberry Pi’s introduced its first product targeted at AI use cases in early June, and its leadership says that it’s already seeing signs for optimism.</p>
<p>The company’s AI Kit is an accessory designed to be paired with the Raspberry Pi 5, the company’s newest computer model. Although it only came to market about three months ago, Raspberry Pi’s CEO Eben Upton said, “We’ve seen very, very robust demand for this product.”</p>
<p>“With accessory products like this, it’s always a little bit hard for us to tell whether these are going to be niche products or mass market products. I think our conclusion is that this is a mass market product,” Upton explained at a analyst briefing Tuesday.</p>
<p>[<a href="https://www.forbes.com/sites/robertolsen-1/2024/09/24/computer-maker-raspberry-pi-sees-robust-demand-for-first-ai-product/]">https://www.forbes.com/sites/robertolsen-1/2024/09/24/computer-maker-raspberry-pi-sees-robust-demand-for-first-ai-product/]</a></p>
<h3 id="editors-note-3"><a class="header-link" href="#editors-note-3"></a>Editor&#39;s Note</h3>
<p>Would love to get my hand on one of these to see what it actually can do. </p>
<h2 id="meta-ai-drops-multimodal-llama-32--heres-why-its-such-a-big-deal"><a class="header-link" href="#meta-ai-drops-multimodal-llama-32--heres-why-its-such-a-big-deal"></a>Meta AI drops multimodal Llama 3.2 — here&#39;s why it&#39;s such a big deal</h2>
<p>Meta has just dropped a new version of its Llama family of large language models. The updated Llama 3.2 introduces multimodality, enabling it to understand images in addition to text. It also brings two new ‘tiny’ models into the family.</p>
<p>Llama is significant—not necessarily because it&#39;s more powerful than models from OpenAI or Google, although it does give them a run for their money—but because it&#39;s open source and accessible to nearly anyone with relative ease.</p>
<p>The update introduces four different model sizes. The 1 billion parameter model runs comfortably on an M3 MacBook Air with 8GB of RAM, while the 3 billion model also works but just barely. These are both text only but can be run on a wider range of devices and offline.</p>
<p>[<a href="https://www.tomsguide.com/ai/meta-drops-multimodal-llama-32-heres-why-its-such-a-big-deal]">https://www.tomsguide.com/ai/meta-drops-multimodal-llama-32-heres-why-its-such-a-big-deal]</a></p>
<h3 id="editors-note-4"><a class="header-link" href="#editors-note-4"></a>Editor&#39;s Note</h3>
<p>This is exciting news to open source community. Lots of enterprise customers like to have control over foundation models. Llama offers the possibility. </p>
    </article>
  </body>
</html>
