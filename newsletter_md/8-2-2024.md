# Xu's AI Newsletter Aug 2, 2024
## Investors Are Suddenly Getting Very Concerned That AI Isn't Making Any Serious Money

An increasing number of Silicon Valley investors and Wall Street analysts are starting to ring the alarm bells over the countless billions of dollars being invested in AI, an overconfidence they warn could result in a massive bubble.

As the Washington Post reports, investment bankers are singing a dramatically different tune than last year, a period marked by tremendous hype surrounding AI, and are instead starting to become wary of Big Tech's ability to actually turn the tech into a profitable business.

[https://futurism.com/investors-concerned-ai-making-money](https://futurism.com/investors-concerned-ai-making-money)

### Editor's Note
Any new technology revolution will go through hype growth period before it will turn into more steady growth. Is hype growth over? Probably not. But we are probably in the second half of hype growth period. 

## Faulty Nvidia H100 GPUs and HBM3 memory caused half of failures during LLama 3 training — one failure every three hours for Meta's 16,384 GPU training cluster

Meta recently released a study detailing its Llama 3 405B model training run on a cluster containing 16,384 Nvidia H100 80GB GPUs. The training run took place over 54 days and the cluster encountered 419 unexpected component failures during that time, averaging one failure every three hours. In half of the failure cases, GPUs or their onboard HBM3 memory were to blame.  

As the old supercomputing adage goes, the only certainty with large-scale systems is failure. Supercomputers are extremely complex devices that use tens of thousands of processors, hundreds of thousands of other chips, and hundreds of miles of cables. In a sophisticated supercomputer, it's normal for something to break down every few hours, and the main trick for developers is to ensure that the system remains operational regardless of such local breakdowns.

The scale and synchronous nature of 16,384 GPU training make it prone to failures. If the failures aren't mitigated correctly, a single GPU failure can disrupt the entire training job, necessitating a restart. However, the Llama 3 team maintained over a 90% effective training time. 

[https://www.tomshardware.com/tech-industry/artificial-intelligence/faulty-nvidia-h100-gpus-and-hbm3-memory-caused-half-of-the-failures-during-llama-3-training-one-failure-every-three-hours-for-metas-16384-gpu-training-cluster](https://www.tomshardware.com/tech-industry/artificial-intelligence/faulty-nvidia-h100-gpus-and-hbm3-memory-caused-half-of-the-failures-during-llama-3-training-one-failure-every-three-hours-for-metas-16384-gpu-training-cluster)

### Editor's Note
The law of big number rears its head here. Massive parallel training makes failure as certainty. This calls for even higher reliability of GPU or NPU design to improve the effective training time. 

## AI training costs are growing exponentially —  IBM says quantum computing could be a solution

Earlier this month, the Wall Street Journal reported that a third of nuclear power plants are in talks with tech companies to power their new data centers. Meanwhile, Goldman Sachs projected that AI is going to drive a 160% increase in power usage by data centers from now until 2030. That is going to take carbon dioxide emissions to more than double current levels. Each ChatGPT query is estimated to take at least 10 times as much energy as a Google search.  The question is: will the exponentially growing cost of training AI models ultimately limit the potential of AI?

Garcia’s work is centered on the ways quantum and AI interface with each other, and the takeaways have great promise. Quantum computing offers potential resource savings and speed benefits. Quantum machine learning can be used for AI in three ways, Garcia said: quantum models on classical data, quantum models on quantum data and classical models on quantum data.

“There have been different theoretical proofs in each of those different categories to show there’s an advantage to using quantum computers for tackling these types of areas,” Garcia said. “For example, if you have limited trainng data or very sparse data, or very interconnected data. One of the areas we’re thinking about that’s very promising in this space is thinking about healthcare and life sciences applications. Anything where you have something quantum mechanical in nature that you need to tackle.”

[https://venturebeat.com/ai/ai-training-costs-are-growing-exponentially-ibm-says-quantum-computing-could-be-a-solution/](https://venturebeat.com/ai/ai-training-costs-are-growing-exponentially-ibm-says-quantum-computing-could-be-a-solution/)

### Editor's Note

AI + Quantum Computing probably will produce super intelligence. When this happens, what would be the role of human kind in this new world?

## Nvidia’s latest AI offering could spark a custom model gold rush

Nvidia quietly unveiled its new AI Foundry service on Tuesday, aiming to help businesses create and deploy custom large language models tailored to their specific needs. The move signals Nvidia’s push to capture a larger share of the booming enterprise AI market.

The AI Foundry combines Nvidia’s hardware, software tools, and expertise to enable companies to develop customized versions of popular open-source models like Meta’s recently released Llama 3.1. This service arrives as businesses increasingly seek to harness the power of generative AI while maintaining control over their data and applications.

[https://venturebeat.com/ai/nvidias-latest-ai-offering-could-spark-a-custom-model-gold-rush/](https://venturebeat.com/ai/nvidias-latest-ai-offering-could-spark-a-custom-model-gold-rush/)

### Editor's Note

Businesses, eventually individuals, demand more control over models. More and more hardware improvement will make training and host custom models possible. 

## Mistral shocks with new open model Mistral Large 2, taking on Llama 3.1

The AI race is picking up pace like never before. Following Meta’s move just yesterday to launch its new open source Llama 3.1 as a highly competitive alternative to leading closed-source “frontier” models, French AI startup Mistral has also thrown its hat in the ring.

The startup announced the next generation of its flagship open source model with 123 billion parameters: Mistral Large 2. However, in an important caveat, the model is only licensed as “open” for non-commercial research uses, including open weights, allowing third-parties to fine-tune it to their liking.

[https://venturebeat.com/ai/mistral-shocks-with-new-open-model-mistral-large-2-taking-on-llama-3-1/](https://venturebeat.com/ai/mistral-shocks-with-new-open-model-mistral-large-2-taking-on-llama-3-1/)

### Editor's Note

It is not surprising we have more competition of open source models. Race just started. 

## Forget coding bootcamps: Airtable’s AI can build your app in seconds

Airtable, the $11 billion no-code platform unicorn, has unveiled Cobuilder, an AI-powered tool that generates customizable applications in seconds using natural language prompts. This launch could reshape the landscape of enterprise software development by allowing non-technical employees to build complex applications without coding knowledge.

Kelly O’Shaughnessy, head of core product and product lead for Airtable Cobuilder, explained the tool’s significance in an interview with VentureBeat. “Cobuilder is the fastest way to build no-code applications, making it possible to create customizable apps with natural language in just seconds,” she said. “Paired with the vast amounts of knowledge across industries, use cases, and business concepts that today’s LLMs have, Cobuilder helps anyone take an idea from concept to reality in seconds and transform their workflows.”

[https://venturebeat.com/ai/forget-coding-bootcamps-airtables-ai-can-build-your-app-in-seconds/](https://venturebeat.com/ai/forget-coding-bootcamps-airtables-ai-can-build-your-app-in-seconds/)

### Editor's Note

Is this beginning of the end of programming jobs?

## In the age of AI, there's no future for workers content with being code monkeys — and they know it

Software engineers know that the days of simply being able to code are behind them.

After all, artificial intelligence taking over jobs is not new — numerous tech giants over the past two years announced that they were axing jobs to focus more on artificial intelligence development.

Last year, Google slashed 12,000 jobs — 6% of its then workforce — as the company began shifting its priorities toward AI.

In May 2023, IBM announced that it would pause hiring for roles that could be replaced by AI. The affected roles, which amounted to 26,000 jobs, included those in human resources and other non-consumer-facing departments.

[https://www.businessinsider.com/with-ai-theres-no-future-for-slow-moving-code-monkeys-2024-7](https://www.businessinsider.com/with-ai-theres-no-future-for-slow-moving-code-monkeys-2024-7)

### Editor's Note

Despite the scary title, in reality, it is still not clear whether AI creates more jobs than it destroys. 

## NVIDIA Announces Generative AI Models and NIM Microservices for OpenUSD Language, Geometry, Physics and Materials

NVIDIA today announced major advancements to Universal Scene Description, or OpenUSD, that will expand adoption of the universal 3D data interchange framework to robotics, industrial design and engineering, and accelerate developers’ abilities to build highly accurate virtual worlds for the next evolution of AI.

Through new OpenUSD-based generative AI and NVIDIA-accelerated development frameworks built on the NVIDIA Omniverse™ platform, more industries can now develop applications for visualizing industrial design and engineering projects, and for simulating environments to build the next wave of physical AI and robots.

The new offerings include NVIDIA NIM™ microservices for AI models that can generate OpenUSD language to answer user queries, generate OpenUSD Python code, apply materials to 3D objects, and understand 3D space and physics to help accelerate digital twin development. In addition, new USD connectors to robotics and industrial simulation data formats and developer tools let users stream massive, fully NVIDIA RTX™ ray-traced datasets to Apple Vision Pro.

“The generative AI boom for heavy industries is here,” said Rev Lebaredian, vice president of Omniverse and simulation technology at NVIDIA. “Until recently, digital worlds have been primarily used by creative industries; now, with the enhancements and accessibility NVIDIA NIM microservices are bringing to OpenUSD, industries of all kinds can build physically based virtual worlds and digital twins to drive innovation while preparing for the next wave of AI: robotics.”

[https://nvidianews.nvidia.com/news/nvidia-announces-generative-ai-models-and-nim-microservices-for-openusd](https://nvidianews.nvidia.com/news/nvidia-announces-generative-ai-models-and-nim-microservices-for-openusd)

### Editor's Note

AI goes to the physical world. 

## OpenAI launches experimental GPT-4o Long Output model with 16X token capacity

OpenAI is reportedly eyeing a cash crunch, but that isn’t stopping the preeminent generative AI company from continuing to release a steady stream of new models and updates.

Yesterday, the company quietly posted a webpage announcing a new large language model (LLM): GPT-4o Long Output, which is a variation on its signature GPT-4o model from May, but with a massively extended output size: up to 64,000 tokens of output instead of GPT-4o’s initial 4,000 — a 16-fold increase.

[https://venturebeat.com/ai/openai-launches-experimental-gpt-4o-long-output-model-with-16x-token-capacity/](https://venturebeat.com/ai/openai-launches-experimental-gpt-4o-long-output-model-with-16x-token-capacity/)

### Editor's Note

64K output tokens is the longest in the industry. 8 times of 8k output token provided by Claude and Gemini.

## OpenAI May Post $5 Billion Loss This Year, Run Out Of Cash In 12 Months

OpenAI May Post $5 Billion Loss This Year, Run Out Of Cash In 12 Months: Report
OpenAI spends most of its money on Microsoft cloud servers (AI Generated Image)


OpenAI is set to burn all of its cash at current expenditures in 12 months' time, according to a report by The Information. The San Francisco based AI startup leader is on track to lose $5 billion, mainly due to high capital expenditure on cloud infrastructure required for training and running AI programs, including that for ChatGPT.

OpenAI has long relied on Microsoft for providing computing infrastructure for running its AI programs. Microsoft was also one of the earliest investors, with a $1 billion investment, three years before the launch of ChatGPT.

The $80 billion market valued company OpenAI has around 350,000 Nvidia A100 chips for running its programs (for inference alone), with 290,000 of those specifically for running ChatGPT, a source told The Information. These servers containing A100s are rented to OpenAI at $1.3 per hour by Microsoft, resulting in $4 Billion of estimated expenditure on these servers in 2024 alone.

[https://www.ndtv.com/india-ai/openai-microsoft-sam-altman-openai-may-post-5-billion-loss-this-year-run-out-of-cash-in-12-months-report-6239442](https://www.ndtv.com/india-ai/openai-microsoft-sam-altman-openai-may-post-5-billion-loss-this-year-run-out-of-cash-in-12-months-report-6239442)

### Editor's Note

OpenAI is losing a lot of money hosting models on Azure platform. Are other model hosting providers making money? Nvidia is probably the only company who reaps most of the profits from the AI hyper growth right now. 

## AI pilots will soon join the Air Force

Artificial intelligence technology used by the U.S. Air Force is usually operated on the ground. Now it’s moving to the sky. The U.S. Air Force has awarded contracts to five developers of AI systems for its new “robot wingmen.”

The AI-powered, unmanned aircraft will fly alongside human-operated fighter jets. Their development is part of the Air Force’s Collaborative Combat Aircraft program, which aims to put 1,000 of the so-called robot wingmen in the sky by 2030. The recipients of the contracts for AI systems development are unknown, but the actual aircraft will be manufactured by General Atomics and Anduril. The drone-maker and military tech startup are developing prototypes.

[https://qz.com/us-air-force-ai-pilots-robot-wingmen-1851609105](https://qz.com/us-air-force-ai-pilots-robot-wingmen-1851609105#:~:text=The%20AI%2Dpowered%2C%20unmanned%20aircraft,in%20the%20sky%20by%202030.)

### Editor's Note

Are we at the dawn of the era of Terminators?

## MICROSOFT IS LOSING A STAGGERING AMOUNT OF MONEY ON AI

Microsoft has spent a staggering amount of money on AI — and serious profits likely remain many years out, if they're ever realized.

The tech giant revealed that during the quarter ending in June, it spent an astonishing $19 billion in cash capital expenditures and equipment, the Wall Street Journal reports — the equivalent of what it used to spend in a whole year a mere five years ago.

Unsurprisingly, most of those $19 billion were related to AI, and roughly half was used for building out and leasing data centers.

[https://futurism.com/the-byte/microsoft-losing-money-ai](https://futurism.com/the-byte/microsoft-losing-money-ai)

### Editor's Note

Echos the money losing venture OpenAI currently operates. People starts to have doubts of profitability of AI. Does this indicate that it is the time to double down?

[July 26th Newsletter](7-26-2024.md)



